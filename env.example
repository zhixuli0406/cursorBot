# ========================================
# CursorBot Environment Configuration
# ========================================

# Telegram Bot Settings (required)
TELEGRAM_BOT_TOKEN=your_bot_token_here
TELEGRAM_ALLOWED_USERS=123456789,987654321

# ========================================
# Workspace Settings
# ========================================

# Local workspace path for file operations
# This path will be mounted to /workspace in Docker container
# Windows example: C:/Users/YourName/Projects
# macOS example: /Users/yourname/projects
# Linux example: /home/yourname/projects
CURSOR_WORKSPACE_PATH=/path/to/your/projects

# ========================================
# Server Settings
# ========================================

SERVER_HOST=0.0.0.0
SERVER_PORT=8000
DEBUG=false

# ========================================
# Security Settings
# ========================================

SECRET_KEY=your_secret_key_here
SESSION_TIMEOUT=3600

# ========================================
# Database & Logging
# ========================================

DATABASE_PATH=./data/cursorbot.db
LOG_LEVEL=INFO
LOG_FILE_PATH=./logs/cursorbot.log

# ========================================
# Cursor Background Agent Settings
# ========================================

# Enable Background Agent (required for /ask command)
BACKGROUND_AGENT_ENABLED=true

# Cursor API Key (required for Background Agent)
# Get this from: https://cursor.com/dashboard?tab=background-agents
CURSOR_API_KEY=

# Optional: GitHub repository URL for Background Agent tasks
CURSOR_GITHUB_REPO=

# Task timeout and poll interval
BACKGROUND_AGENT_TIMEOUT=300
BACKGROUND_AGENT_POLL_INTERVAL=5

# ========================================
# LLM Provider Settings
# ========================================
# 
# Support multiple AI providers. Configure the ones you want to use.
# Priority (if DEFAULT_LLM_PROVIDER not set):
#   OpenRouter > OpenAI > Anthropic > Google > Ollama > Custom
#

# --- Default Provider ---
# Set to force a specific provider: openai, google, anthropic, openrouter, ollama, custom
DEFAULT_LLM_PROVIDER=
# Optional: Override the default model for the chosen provider
DEFAULT_LLM_MODEL=

# --- OpenAI ---
# Get API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=
OPENAI_API_BASE=https://api.openai.com/v1
# Models: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo, o1-preview, o1-mini
OPENAI_MODEL=gpt-4o-mini

# --- Google Gemini ---
# Get API key from: https://aistudio.google.com/apikey
GOOGLE_GENERATIVE_AI_API_KEY=
# Models: gemini-2.0-flash, gemini-2.0-flash-exp, gemini-1.5-pro, gemini-1.5-flash, gemini-pro
GOOGLE_MODEL=gemini-2.0-flash

# --- Anthropic Claude ---
# Get API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=
ANTHROPIC_API_BASE=https://api.anthropic.com/v1
# Models: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022, claude-3-opus-20240229
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# --- OpenRouter (Proxy to multiple models) ---
# Get API key from: https://openrouter.ai/keys
# Recommended for access to multiple models with one key
OPENROUTER_API_KEY=
# Free models:
#   - google/gemini-2.0-flash-exp:free (recommended)
#   - meta-llama/llama-3.2-3b-instruct:free
#   - qwen/qwen-2-7b-instruct:free
# Paid models:
#   - anthropic/claude-3.5-sonnet
#   - openai/gpt-4o
#   - google/gemini-pro-1.5
OPENROUTER_MODEL=google/gemini-2.0-flash-exp:free

# --- Ollama (Local Models) ---
# Install Ollama from: https://ollama.ai/
# Run: ollama pull llama3.2
OLLAMA_ENABLED=false
OLLAMA_API_BASE=http://localhost:11434
# Models: llama3.2, llama3.1, mistral, codellama, phi3, qwen2.5, deepseek-coder-v2
OLLAMA_MODEL=llama3.2

# --- Custom OpenAI-Compatible Endpoint ---
# For self-hosted models or alternative APIs (LM Studio, vLLM, etc.)
CUSTOM_API_KEY=
CUSTOM_API_BASE=
CUSTOM_MODEL=default

# --- AI General Settings ---
CUSTOM_PROMPT=
AI_MAX_TOKENS=4096
AI_TEMPERATURE=0.7

# ========================================
# TTS (Text-to-Speech) Settings (Optional)
# ========================================

# --- ElevenLabs (High Quality) ---
# Get API key from: https://elevenlabs.io/
ELEVENLABS_API_KEY=

# Default TTS provider: openai, edge, elevenlabs
DEFAULT_TTS_PROVIDER=edge

# Default TTS voice
# OpenAI: alloy, echo, fable, onyx, nova, shimmer
# Edge: zh-TW-HsiaoChenNeural, en-US-JennyNeural, etc.
# ElevenLabs: rachel, domi, bella, antoni, etc.
DEFAULT_TTS_VOICE=

# ========================================
# OAuth Settings (Optional)
# ========================================

# --- GitHub OAuth ---
GITHUB_CLIENT_ID=
GITHUB_CLIENT_SECRET=
GITHUB_OAUTH_REDIRECT_URI=http://localhost:8000/oauth/github/callback

# --- Google OAuth ---
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
GOOGLE_OAUTH_REDIRECT_URI=http://localhost:8000/oauth/google/callback

# --- Discord OAuth ---
DISCORD_CLIENT_ID=
DISCORD_CLIENT_SECRET=
DISCORD_OAUTH_REDIRECT_URI=http://localhost:8000/oauth/discord/callback

# ========================================
# Sandbox Settings (Optional)
# ========================================

# Default sandbox type: subprocess, docker, restricted
DEFAULT_SANDBOX_TYPE=subprocess

# Sandbox execution timeout (seconds)
SANDBOX_TIMEOUT=30

# Docker sandbox settings
SANDBOX_MEMORY_LIMIT=256m
SANDBOX_CPU_LIMIT=1.0
SANDBOX_NETWORK_ENABLED=false

# ========================================
# Queue & Heartbeat Settings (Optional)
# ========================================

# Task queue settings
QUEUE_MAX_CONCURRENT=5
QUEUE_DEFAULT_TIMEOUT=300

# Heartbeat monitoring interval (seconds)
HEARTBEAT_INTERVAL=30

# ========================================
# Discord Bot Settings (Optional)
# ========================================

# Enable Discord bot
DISCORD_ENABLED=false

# Discord bot token
# Get from: https://discord.com/developers/applications
DISCORD_BOT_TOKEN=

# Allowed Discord guild (server) IDs (comma-separated)
DISCORD_ALLOWED_GUILDS=

# Allowed Discord user IDs (comma-separated)
DISCORD_ALLOWED_USERS=
